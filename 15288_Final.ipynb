{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15288_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2YfwnvVwyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deff76e9-68c3-49af-a9c2-b6445437b8fd"
      },
      "source": [
        "!pip install instagram-scraper"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting instagram-scraper\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/5b/b5eee5adef1077bbc9990c788ba3d9b697d19c36355d49ce11084fd29d87/instagram-scraper-1.9.1.tar.gz\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from instagram-scraper) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from instagram-scraper) (4.41.1)\n",
            "Collecting moviepy>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->instagram-scraper) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->instagram-scraper) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->instagram-scraper) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->instagram-scraper) (2020.12.5)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy>=1.0.0->instagram-scraper) (4.4.2)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from moviepy>=1.0.0->instagram-scraper) (1.19.5)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 32.5MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/0f/4b49476d185a273163fa648eaf1e7d4190661d1bbf37ec2975b84df9de02/imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9MB 150kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.5->moviepy>=1.0.0->instagram-scraper) (7.1.2)\n",
            "Building wheels for collected packages: instagram-scraper, moviepy, proglog\n",
            "  Building wheel for instagram-scraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for instagram-scraper: filename=instagram_scraper-1.9.1-cp37-none-any.whl size=35931 sha256=a266e393a14592c9efe8b8877bebf03e2bd130e92dd2bbf08fad97f724ebb853\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/b5/0a/90c1b539b2f4baa66e816f34a87e8416a7ad7e641adf9377ba\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-cp37-none-any.whl size=110728 sha256=34d3639dbb9034db5de5768884621ebebb0741a6a7e5720cedc6edaab8c9316b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-cp37-none-any.whl size=6148 sha256=3b2569349eb8a1412140f1a8b30e960ade956f862220efffcfd44121c8edba79\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n",
            "Successfully built instagram-scraper moviepy proglog\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: proglog, imageio, imageio-ffmpeg, moviepy, instagram-scraper\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "Successfully installed imageio-2.9.0 imageio-ffmpeg-0.4.3 instagram-scraper-1.9.1 moviepy-1.0.3 proglog-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlrLgE6kXeG-"
      },
      "source": [
        "import instagram_scraper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "7qTUC2nGXhCv",
        "outputId": "9bed9db0-22e9-4122-b87b-0430e9bcbdba"
      },
      "source": [
        "temp = instagram-scraper noodleheadpgh\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-0fc7b026a602>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    temp = instagram-scraper noodleheadpgh\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIp7s4ds14JB"
      },
      "source": [
        "# **Yelp and Instagram: Attempting to predict the best rating and post engagement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_SMOkr50f1"
      },
      "source": [
        "# **Group Members and andrew ids:**\n",
        "\n",
        "Sanjana Jobalia: sjobalia\n",
        "\n",
        "Aditya Arun: aditya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O5NvFfg18Dk"
      },
      "source": [
        "# Introduction:\n",
        "\n",
        "Our final project is aimed at trying to explore how well Pittsburgh resturants do on social media and websites, namely Yelp and Instagram. On Yelp, each restaurant is given an overall rating ranging from 1 to 5. These restaurants also have instagram pages where they make posts about their resturants, and these posts recieve likes, comments and views from their follower base. We want to create machine learning models that will allow us to predict the ratings restaurants recieve on Yelp, provided a resturant has certain features. Additionally, we will attempt to use machine learning models to predict how well their posts engage with their followers on instagram. This enables us to answer the overaching question of what steps can restaurants take to improve their Yelp and instagram presence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_EygJ-d5dAH"
      },
      "source": [
        "# Table of Contents:\n",
        "**Yelp:**\n",
        "\n",
        "Collecting data using Yelp API\n",
        "\n",
        "Extracting features\n",
        "\n",
        "Feature Analysis\n",
        "\n",
        "Feature Engineering\n",
        "\n",
        "Creating machine learning model\n",
        "\n",
        "Cross validating our model\n",
        "\n",
        "Choosing the most appropriate model\n",
        "\n",
        "Predicting ratings\n",
        "\n",
        "Testing accuracy\n",
        "\n",
        "**Instagram:**\n",
        "\n",
        "**Conclusion and Discussions:**\n",
        "\n",
        "**References**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmNg_Auj10Co"
      },
      "source": [
        "#Scraping\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import pickle\n",
        "#Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from collections import Counter\n",
        "import scipy.stats as stats\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Ts_VUOKYBuV5",
        "outputId": "51d2dfac-9763-453e-b81a-810415f06738"
      },
      "source": [
        "API_URL = \"https://api.yelp.com/v3/businesses\"\n",
        "SEARCH_URL = API_URL + \"/search\"\n",
        "RESTAURANT_IDS = \"rid.pkl\"\n",
        "ZIPCODE_BOROUGH_DICT = np.load('zipcode_borough_dict.npy').item()\n",
        "\n",
        "with open(\"./API_KEY\", 'r') as f:\n",
        "    api_key = f.readline().strip()\n",
        "API_HEADERS = {\n",
        "    'Authorization': ' '.join(['Bearer', api_key])\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9c2a2907dd51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSEARCH_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPI_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/search\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRESTAURANT_IDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rid.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mZIPCODE_BOROUGH_DICT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zipcode_borough_dict.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./API_KEY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'zipcode_borough_dict.npy'"
          ]
        }
      ]
    }
  ]
}